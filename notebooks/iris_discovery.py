# -*- coding: utf-8 -*-
"""Iris_Discovery

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XAC506-sQjwvVVlQePHUNgKAG2AwsY9r
"""

from sklearn.datasets import load_iris
import pandas as pd

# Load dataset từ sklearn
iris = load_iris()

# Chuyển sang DataFrame
df = pd.DataFrame(iris.data, columns=iris.feature_names)
df['target'] = iris.target
df['target_name'] = df['target'].apply(lambda x: iris.target_names[x])

# Xem 5 dòng đầu tiên
df.head()

import pandas as pd
from sklearn.datasets import load_iris

# Load dữ liệu Iris
iris = load_iris()
df = pd.DataFrame(iris.data, columns=iris.feature_names)
df["target"] = iris.target
df["target_name"] = df["target"].apply(lambda x: iris.target_names[x])

# Thống kê mô tả cơ bản
df.describe()

import pandas as pd
from sklearn.datasets import load_iris

# Load dữ liệu Iris
iris = load_iris()
df = pd.DataFrame(iris.data, columns=iris.feature_names)
df["target"] = iris.target
df["target_name"] = df["target"].apply(lambda x: iris.target_names[x])

# Thống kê mô tả cơ bản
df.describe()

import pandas as pd
from sklearn.datasets import load_iris

# Load dữ liệu Iris
iris = load_iris()
df = pd.DataFrame(iris.data, columns=iris.feature_names)
df["target"] = iris.target
df["target_name"] = df["target"].apply(lambda x: iris.target_names[x])

# Thống kê mô tả cơ bản
df.describe()

df.info()

import seaborn as sns
import matplotlib.pyplot as plt

# Phân phối các biến đầu vào theo biểu đồ histogram
df.drop(columns=["target", "target_name"]).hist(bins=20, figsize=(10,6), color='skyblue')
plt.suptitle("Phân phối của các đặc trưng")
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns

# Vẽ histogram cho từng đặc trưng
df_features = df.drop(columns=['target', 'target_name'])
df_features.hist(bins=20, figsize=(10, 6), color='skyblue', edgecolor='black')
plt.suptitle("Biểu đồ phân phối (Histogram) của các đặc trưng", y=1.02)
plt.tight_layout()
plt.show()

df.isnull().sum()

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(10, 6))
sns.boxplot(data=df.drop(columns=["target", "target_name"]), palette="Set2")
plt.title("Boxplot các đặc trưng để phát hiện giá trị ngoại lai")
plt.xlabel("Đặc trưng")
plt.ylabel("Giá trị")
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(10, 6))
sns.boxplot(data=df.drop(columns=["target", "target_name"]), palette="Set2")
plt.title("Boxplot các đặc trưng để phát hiện giá trị ngoại lai")
plt.xlabel("Đặc trưng")
plt.ylabel("Giá trị")
plt.grid(True)
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(8, 6))
sns.heatmap(df.corr(numeric_only=True), annot=True, cmap='coolwarm', fmt=".2f")
plt.title("Ma trận tương quan giữa các đặc trưng và biến mục tiêu (target)")
plt.show()

sns.pairplot(df, hue="target_name", diag_kind="kde")
plt.suptitle("Mối quan hệ giữa các đặc trưng và nhãn mục tiêu", y=1.02)
plt.show()

sns.scatterplot(data=df, x="petal length (cm)", y="petal width (cm)", hue="target_name", palette="Set1")
plt.title("Petal Length vs Petal Width theo từng loài hoa")
plt.xlabel("Petal Length (cm)")
plt.ylabel("Petal Width (cm)")
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt

sns.pairplot(df, hue="target_name", diag_kind="kde")
plt.suptitle("Mối quan hệ giữa các đặc trưng theo từng loài Iris", y=1.02)
plt.show()

# Tần suất (số lượng từng loài)
count_per_class = df['target_name'].value_counts()

# Tỷ lệ phần trăm từng loài
percent_per_class = df['target_name'].value_counts(normalize=True) * 100

# Kết hợp lại thành một bảng
summary = pd.DataFrame({
    'Count': count_per_class,
    'Percentage (%)': percent_per_class.round(2)
})

print(summary)

for col in df.columns[:4]:
    plt.figure(figsize=(6, 4))
    sns.violinplot(data=df, x="target_name", y=col, palette="Pastel1")
    plt.title(f"Violin Plot: {col} theo từng loài Iris")
    plt.xlabel("Loài hoa")
    plt.ylabel(col)
    plt.grid(True)
    plt.tight_layout()
    plt.show()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Đếm số lượng mỗi nhãn
count_df = df['target_name'].value_counts().reset_index()
count_df.columns = ['Loài hoa', 'Số lượng']

# Hiển thị
print(count_df)

sns.countplot(data=df, x='target_name', palette='Set2')
plt.title("Tần suất xuất hiện của từng loài hoa Iris")
plt.xlabel("Loài hoa")
plt.ylabel("Số lượng")
plt.grid(True, axis='y')
plt.tight_layout()
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt

for col in df.columns[:4]:  # Chạy qua 4 đặc trưng đầu vào
    plt.figure(figsize=(6, 4))
    sns.violinplot(data=df, x='target_name', y=col, palette='Pastel1')
    plt.title(f"Violin Plot: {col} theo từng loài hoa")
    plt.xlabel("Loài hoa")
    plt.ylabel(col)
    plt.grid(True)
    plt.tight_layout()
    plt.show()

def validate_input_features(df):
    errors = []

    # Định nghĩa schema mong muốn
    schema = {
        'sepal length (cm)': {'dtype': float, 'min': 4.3, 'max': 7.9},
        'sepal width (cm)':  {'dtype': float, 'min': 2.0, 'max': 4.4},
        'petal length (cm)': {'dtype': float, 'min': 1.0, 'max': 6.9},
        'petal width (cm)':  {'dtype': float, 'min': 0.1, 'max': 2.5}
    }

    # Kiểm tra tên cột và kiểu dữ liệu
    for col, rules in schema.items():
        if col not in df.columns:
            errors.append(f"Thiếu cột: {col}")
        else:
            if not pd.api.types.is_float_dtype(df[col]):
                errors.append(f"Cột '{col}' không phải kiểu float.")

            # Kiểm tra giá trị ngoài phạm vi
            if not df[col].between(rules['min'], rules['max']).all():
                errors.append(
                    f"Cột '{col}' có giá trị ngoài khoảng [{rules['min']}, {rules['max']}]."
                )

    return errors

errors = validate_input_features(df)

if errors:
    print("Dữ liệu không hợp lệ:")
    for err in errors:
        print("-", err)
else:
    print("Dữ liệu hợp lệ: 4 đặc trưng đầu vào đúng định dạng và phạm vi.")

def validate_json_input(json_data):
    errors = []

    # Định nghĩa schema
    schema = {
        'sepal length (cm)': {'min': 4.3, 'max': 7.9},
        'sepal width (cm)':  {'min': 2.0, 'max': 4.4},
        'petal length (cm)': {'min': 1.0, 'max': 6.9},
        'petal width (cm)':  {'min': 0.1, 'max': 2.5}
    }

    # Kiểm tra từng bản ghi trong JSON
    for i, record in enumerate(json_data):
        for field, rules in schema.items():
            if field not in record:
                errors.append(f"Dòng {i+1}: Thiếu trường '{field}'")
                continue
            value = record[field]
            if not isinstance(value, (int, float)):
                errors.append(f"Dòng {i+1}: Trường '{field}' phải là số (int hoặc float), nhưng nhận {type(value).__name__}")
            elif not (rules['min'] <= value <= rules['max']):
                errors.append(f"Dòng {i+1}: Giá trị '{field}' = {value} nằm ngoài [{rules['min']}, {rules['max']}]")

    return errors

json_ok = [
    {
        "sepal length (cm)": 5.1,
        "sepal width (cm)": 3.5,
        "petal length (cm)": 1.4,
        "petal width (cm)": 0.2
    },
    {
        "sepal length (cm)": 6.3,
        "sepal width (cm)": 2.9,
        "petal length (cm)": 5.6,
        "petal width (cm)": 2.2
    }
]

json_error = [
    {
        "sepal length (cm)": 8.5,                # sai: > 7.9
        "sepal width (cm)": "wide",              # sai: không phải số
        "petal length (cm)": 1.3,
        "petal width (cm)": 0.2
    },
    {
        "sepal width (cm)": 3.0,                 # sai: thiếu sepal length
        "petal length (cm)": 0.5,                # sai: < 1.0
        "petal width (cm)": 3.5,                 # sai: > 2.5
        "sepal length (cm)": 5.0
    }
]

for name, data in [('json_ok', json_ok), ('json_error', json_error)]:
    print(f"\n>>> Kiểm tra: {name}")
    issues = validate_json_input(data)
    if issues:
        for issue in issues:
            print("-", issue)
    else:
        print("Dữ liệu hợp lệ!")

import pandas as pd
import numpy as np
from sklearn.datasets import load_iris

# Tải dữ liệu gốc
iris = load_iris()
df = pd.DataFrame(iris.data, columns=iris.feature_names)

# Giả lập thiếu dữ liệu
df_missing = df.copy()
df_missing.loc[0, 'sepal length (cm)'] = np.nan
df_missing.loc[5, 'petal width (cm)'] = np.nan
df_missing.loc[10, 'sepal width (cm)'] = np.nan
df_missing.loc[20, 'petal length (cm)'] = np.nan

# Lặp qua từng cột đặc trưng và điền trung bình
for col in df.columns:
    df_missing[col] = df_missing[col].fillna(df[col].mean())

print(df_missing.isnull().sum())

import pandas as pd
import numpy as np
from sklearn.datasets import load_iris

# Tải dữ liệu gốc
iris = load_iris()
df = pd.DataFrame(iris.data, columns=iris.feature_names)

# Thêm cột phân loại giả lập
np.random.seed(42)
df['flower_type'] = np.random.choice(['A', 'B', 'C'], size=len(df))

df.head()

from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()
df['flower_type_encoded'] = le.fit_transform(df['flower_type'])

df.head()

from sklearn.datasets import load_iris
import pandas as pd

# Load dữ liệu
iris = load_iris()
df = pd.DataFrame(iris.data, columns=iris.feature_names)

# Chỉ lấy 4 cột đầu vào để chuẩn hóa
features = df.columns[:4]

from sklearn.preprocessing import StandardScaler

scaler_std = StandardScaler()
df_standardized = df.copy()
df_standardized[features] = scaler_std.fit_transform(df[features])

print("StandardScaler:\n", df_standardized[features].describe())

df_fe = df.copy()

# Tỷ lệ giữa chiều dài và chiều rộng của lá đài (sepal)
df_fe['sepal_ratio'] = df_fe['sepal length (cm)'] / df_fe['sepal width (cm)']

# Tỷ lệ giữa chiều dài và chiều rộng của cánh hoa (petal)
df_fe['petal_ratio'] = df_fe['petal length (cm)'] / df_fe['petal width (cm)']

# Tổng chiều dài tổng thể (sepal + petal)
df_fe['total_length'] = df_fe['sepal length (cm)'] + df_fe['petal length (cm)']

# Nhân giữa chiều dài và chiều rộng để tạo diện tích xấp xỉ
df_fe['sepal_area'] = df_fe['sepal length (cm)'] * df_fe['sepal width (cm)']
df_fe['petal_area'] = df_fe['petal length (cm)'] * df_fe['petal width (cm)']

df_fe[['sepal_ratio', 'petal_ratio', 'total_length', 'sepal_area', 'petal_area']].describe()

df_fe[['sepal_ratio', 'petal_ratio', 'total_length', 'sepal_area', 'petal_area']].head()

from sklearn.model_selection import train_test_split

# Chọn đặc trưng đầu vào
X = df[df.columns[:4]]  # 4 đặc trưng gốc
y = iris.target         # Nhãn phân loại: 0, 1, 2

# Chia train/test (80/20)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, accuracy_score

model_lr = LogisticRegression(max_iter=200)
model_lr.fit(X_train, y_train)

y_pred_lr = model_lr.predict(X_test)
print("Logistic Regression Accuracy:", accuracy_score(y_test, y_pred_lr))
print(classification_report(y_test, y_pred_lr, target_names=iris.target_names))

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
# 1. Khởi tạo mô hình
model_rf = RandomForestClassifier(random_state=42)
# 2. Huấn luyện mô hình trên tập train
model_rf.fit(X_train, y_train)
# 3. Dự đoán nhãn cho tập test
y_pred_rf = model_rf.predict(X_test)
# 4. Đánh giá mô hình
print("Random Forest Accuracy:", accuracy_score(y_test, y_pred_rf))
print(classification_report(y_test, y_pred_rf, target_names=iris.target_names))

from sklearn.datasets import load_iris
import pandas as pd

# Load dataset từ sklearn
iris = load_iris()

# Chuyển sang DataFrame
df = pd.DataFrame(iris.data, columns=iris.feature_names)

# Xem 5 dòng đầu tiên
df.head()

import kagglehub
import pandas as pd
import os

# Download latest version
path = kagglehub.dataset_download("uciml/iris")

# Tạo đường dẫn đầy đủ đến file
csv_path = os.path.join(path, "Iris.csv")

# Đọc dữ liệu
df = pd.read_csv(csv_path)

# Bỏ cột Id
df.drop(columns=["Id"], inplace=True)

# Thống kê mô tả các đặc trưng số
print(df.describe())

print(df.info())

import matplotlib.pyplot as plt
import seaborn as sns

# Cấu hình chung
sns.set(style="whitegrid")
features = ['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']

# Vẽ histogram và boxplot cho từng biến
plt.figure(figsize=(14, 10))
for i, feature in enumerate(features):
    plt.subplot(4, 2, 2*i+1)
    sns.histplot(df[feature], kde=True, bins=20, color="skyblue")
    plt.title(f"Phân bố Histogram: {feature}")

    plt.subplot(4, 2, 2*i+2)
    sns.boxplot(x=df[feature], color="lightgreen")
    plt.title(f"Phân bố Boxplot: {feature}")

plt.tight_layout()
plt.show()

df.isnull().sum()

import matplotlib.pyplot as plt
import seaborn as sns

# Danh sách các biến
features = ['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']

plt.figure(figsize=(12, 8))
for i, feature in enumerate(features):
    plt.subplot(2, 2, i+1)
    sns.boxplot(y=df[feature], color="lightblue")
    plt.title(f"Boxplot: {feature}")
plt.tight_layout()
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt

# Cấu hình
sns.set(style="whitegrid")
features = ['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']

plt.figure(figsize=(12, 10))

for i, feature in enumerate(features):
    plt.subplot(2, 2, i+1)
    sns.violinplot(x="Species", y=feature, data=df, palette="Set2")
    plt.title(f"Violin Plot: {feature} vs Species")
    plt.xlabel("Species")
    plt.ylabel(feature)

plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np

# Đọc dữ liệu Iris từ Kaggle
df = pd.read_csv(csv_path)

# Bỏ cột Id và chỉ giữ 4 cột đặc trưng
df = df.drop(columns=["Id", "Species"])

# Giả lập dữ liệu thiếu
df_missing = df.copy()
df_missing.loc[0, "SepalLengthCm"] = np.nan
df_missing.loc[5, "SepalWidthCm"] = np.nan
df_missing.loc[10, "PetalLengthCm"] = np.nan
df_missing.loc[15, "PetalWidthCm"] = np.nan

print("Dữ liệu có giá trị thiếu:")
print(df_missing.head(20))

# Xử lý từng cột
for col in df_missing.columns:
    mean_val = df_missing[col].mean()
    df_missing[col] = df_missing[col].fillna(mean_val)

print("\nDữ liệu sau khi điền missing value:")
print(df_missing.head(20))

import pandas as pd
import numpy as np

# đọc file từ csv_path của bạn
df = pd.read_csv(csv_path)

# bỏ cột Id nếu có
if 'Id' in df.columns:
    df.drop(columns=['Id'], inplace=True)

# thêm cột flower_type ngay trong bảng
np.random.seed(42)  # để tái lập
df['flower_type'] = np.random.choice(['A', 'B', 'C'], size=len(df))

# hiển thị 5 dòng đầu
df.head()

from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()
df['flower_type_encoded'] = le.fit_transform(df['flower_type'])
# hiển thị 5 dòng đầu
df.head()

from sklearn.preprocessing import StandardScaler, MinMaxScaler

# 4 biến số gốc
numerical_features = ['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']

scaler_std = StandardScaler()

df_std = df.copy()
df_std[numerical_features] = scaler_std.fit_transform(df_std[numerical_features])

print("Dữ liệu chuẩn hóa bằng StandardScaler:")
print(df_std[numerical_features].describe())

def describe_scaled(df, features, method_name="StandardScaler"):

    print(f"\n{method_name}:\n")
    print(df[features].describe())

import kagglehub
import pandas as pd
import os
from sklearn.model_selection import train_test_split

# Download latest version
path = kagglehub.dataset_download("uciml/iris")

# Tạo đường dẫn đầy đủ đến file
csv_path = os.path.join(path, "Iris.csv")

X = df.drop(columns=["Species"])
y = df["Species"]

# Phân chia
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print(f"Train set: {X_train.shape}, Test set: {X_test.shape}")

import kagglehub
import pandas as pd
import os
from sklearn.model_selection import train_test_split

# Tải Iris dataset
path = kagglehub.dataset_download("uciml/iris")

# Tạo đường dẫn đầy đủ
csv_path = os.path.join(path, "Iris.csv")

# Đọc file CSV
df = pd.read_csv(csv_path)

# Chia X và y
X = df.drop(columns=["Species", "Id"])
y = df["Species"]

# Phân chia train/test
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print(f"Train set: {X_train.shape}, Test set: {X_test.shape}")

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report

# Khởi tạo mô hình
model = LogisticRegression(max_iter=200)

# Huấn luyện
model.fit(X_train, y_train)

# Dự đoán trên tập test
y_pred = model.predict(X_test)

# Đánh giá
print(f"Độ chính xác: {accuracy_score(y_test, y_pred):.2f}")
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report

# Khởi tạo mô hình
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)

# Huấn luyện
rf_model.fit(X_train, y_train)

# Dự đoán
y_pred_rf = rf_model.predict(X_test)

# Đánh giá
print(f"Độ chính xác (Random Forest): {accuracy_score(y_test, y_pred_rf):.2f}")
print("\nClassification Report (Random Forest):")
print(classification_report(y_test, y_pred_rf))

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report

# Phân chia dữ liệu với random_state
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# Random Forest với random_state
rf_model = RandomForestClassifier(n_estimators=800, random_state=42)
rf_model.fit(X_train, y_train)

y_pred_rf = rf_model.predict(X_test)

print(f"Độ chính xác (Random Forest): {accuracy_score(y_test, y_pred_rf):.2f}")
print("\nClassification Report (Random Forest):")
print(classification_report(y_test, y_pred_rf))

from sklearn.neighbors import KNeighborsClassifier

knn = KNeighborsClassifier(n_neighbors=3)
knn.fit(X_train, y_train)
y_pred_knn = knn.predict(X_test)
print(f"Độ chính xác (KNN): {accuracy_score(y_test, y_pred_knn):.2f}")
print("\nClassification Report (KNN):")
print(classification_report(y_test, y_pred_knn))

from sklearn.svm import SVC

svm = SVC(kernel='rbf', C=1, gamma='auto')
svm.fit(X_train, y_train)
y_pred_svm = svm.predict(X_test)
print(f"Độ chính xác (Random Forest): {accuracy_score(y_test, y_pred_svm):.2f}")
print("\nClassification Report (Random Forest):")
print(classification_report(y_test, y_pred_svm))